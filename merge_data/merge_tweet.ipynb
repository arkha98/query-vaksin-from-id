{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "\n",
    "# Import Path\n",
    "main_path = '../'\n",
    "query_tweet_path = main_path+'query_tweet/'\n",
    "auth_path = main_path+'auth/'\n",
    "ids_path = main_path+'covid19-indonesian-tweet/ids/'\n",
    "merge_path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet = pd.read_csv(merge_path+'merge_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merge_tweet['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_user_following(list_user_id):\n",
    "    count = 0\n",
    "    # Load auth file\n",
    "    acct_twitter_1 = pd.read_csv(auth_path+'arkha_analytics.csv')\n",
    "    acct_twitter_2 = pd.read_csv(auth_path+'dummy_analytic.csv')\n",
    "    acct_twitter_3 = pd.read_csv(auth_path+'arkha98-dev.csv')\n",
    "    # Authorize our Twitter credentials\n",
    "    auth = tweepy.OAuthHandler(acct_twitter_1.api_key.values[0], acct_twitter_1.api_key_secret.values[0])\n",
    "    auth.set_access_token(acct_twitter_1.access_token.values[0], acct_twitter_1.access_token_secret.values[0])\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    df = pd.DataFrame(columns=['user_id', 'following'])\n",
    "\n",
    "    for user_id in tqdm(list_user_id):\n",
    "        following = api.get_follower_ids(user_id=user_id)\n",
    "        for user in following:\n",
    "            df2 = pd.DataFrame({\"user_id\":[user_id], \"following\":[user]})\n",
    "            df = pd.concat([df, df2], ignore_index=True, sort=False)\n",
    "    return df\n",
    "\n",
    "def query_user_followers(list_user_id):\n",
    "    count = 0\n",
    "    # Load auth file\n",
    "    acct_twitter_1 = pd.read_csv(auth_path+'arkha_analytics.csv')\n",
    "    acct_twitter_2 = pd.read_csv(auth_path+'dummy_analytic.csv')\n",
    "    acct_twitter_3 = pd.read_csv(auth_path+'arkha98-dev.csv')\n",
    "    # Authorize our Twitter credentials\n",
    "    auth = tweepy.OAuthHandler(acct_twitter_1.api_key.values[0], acct_twitter_1.api_key_secret.values[0])\n",
    "    auth.set_access_token(acct_twitter_1.access_token.values[0], acct_twitter_1.access_token_secret.values[0])\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    df = pd.DataFrame(columns=['user_id', 'follower'])\n",
    "\n",
    "    for user_id in tqdm(list_user_id):\n",
    "        followers = api.get_follower_ids(user_id=user_id)\n",
    "        for user in followers:\n",
    "            df2 = pd.DataFrame({\"user_id\":[user_id], \"follower\":[user]})\n",
    "            df = pd.concat([df, df2], ignore_index=True, sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = merge_tweet['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load auth file\n",
    "acct_twitter_1 = pd.read_csv(auth_path+'arkha_analytics.csv')\n",
    "acct_twitter_2 = pd.read_csv(auth_path+'dummy_analytic.csv')\n",
    "acct_twitter_3 = pd.read_csv(auth_path+'arkha98-dev.csv')\n",
    "# Authorize our Twitter credentials\n",
    "auth = tweepy.OAuthHandler(acct_twitter_1.api_key.values[0], acct_twitter_1.api_key_secret.values[0])\n",
    "auth.set_access_token(acct_twitter_1.access_token.values[0], acct_twitter_1.access_token_secret.values[0])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = api.get_follower_ids(user_id=all_id[0])\n",
    "tmp2 = api.get_friend_ids(user_id=all_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_followers = query_user_followers(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_following = query_user_following(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_followers.to_csv(merge_path+'list_followers', index=False)\n",
    "list_following.to_csv(merge_path+'list_following', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge tweet with stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "\n",
    "# Import Path\n",
    "main_path = '../'\n",
    "query_tweet_path = main_path+'query_tweet/'\n",
    "auth_path = main_path+'auth/'\n",
    "ids_path = main_path+'covid19-indonesian-tweet/ids/'\n",
    "merge_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193268/1839917730.py:1: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merge_tweet = pd.read_csv(merge_path+'merge_tweet.csv')\n"
     ]
    }
   ],
   "source": [
    "merge_tweet = pd.read_csv(merge_path+'merge_tweet.csv')\n",
    "labeled_data = pd.read_csv(merge_path+'labeled-all-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet_labeled = merge_tweet.copy()\n",
    "merge_tweet_labeled['stance'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156237/156237 [02:54<00:00, 893.33it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(merge_tweet_labeled.shape[0])):\n",
    "    index = labeled_data.index[labeled_data['id'] == merge_tweet_labeled.loc[i,'id']].tolist()[0]\n",
    "    merge_tweet_labeled.loc[i,'stance'] = labeled_data.loc[index,'stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tweet_labeled.to_csv(merge_path+'merge_tweet_labeled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83f6bfcc771d7640d912d90fc90f3d3c44535298bb0e9fb6c185c6b497046d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
